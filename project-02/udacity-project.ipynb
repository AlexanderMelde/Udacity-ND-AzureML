{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Operationalizing Machine Learning\n",
        "** Project 2 **\n",
        "[[View Rubric](https://review.udacity.com/#!/rubrics/2893/view)]\n",
        "\n",
        "\n",
        "This notebook consists of the following chapters:\n",
        "\n",
        "0. Python Initialization\n",
        "1. Authentication\n",
        "2. Automated ML Experiment\n",
        "3. Deployment\n",
        "4. Enable logging\n",
        "5. Swagger Documentation\n",
        "6. Consume the model endpoints\n",
        "7. Create, Publish and consume a pipeline\n",
        "8. Documentation\n",
        "9. Optional: Benchmarking\n",
        "10. Optional: Cleanup\n",
        "\n",
        "\n",
        "## 0. Python Initialization\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "source": [
        "<div class=\"alert alert-block alert-danger\">\n",
        "<b>Just don't:</b> In general, avoid the red boxes. These should only be\n",
        "used for actions that might cause data loss or another major issue.\n",
        "</div>"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#  Not needed when running notebook on azure:\n",
        "# !pip install --upgrade -q -r requirements.txt\n",
        "# !python --version\n",
        "# may be needed on some azure machines:\n",
        "!pip install pyopenssl"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import os\n",
        "import csv\n",
        "import json\n",
        "import threading\n",
        "\n",
        "import pickle\n",
        "import joblib\n",
        "import pkg_resources\n",
        "import requests\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import sklearn\n",
        "from sklearn import datasets\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "import azureml.core\n",
        "from azureml.core import Model\n",
        "# from azureml.core.model import Model\n",
        "from azureml.core.authentication import InteractiveLoginAuthentication\n",
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "from azureml.core.dataset import Dataset\n",
        "from azureml.data.dataset_factory import TabularDatasetFactory\n",
        "from azureml.core.experiment import Experiment\n",
        "from azureml.core.resource_configuration import ResourceConfiguration\n",
        "from azureml.core.run import Run\n",
        "from azureml.core.webservice import LocalWebservice, Webservice\n",
        "from azureml.core.workspace import Workspace\n",
        "from azureml.pipeline.core import Pipeline, PipelineData, TrainingOutput\n",
        "from azureml.pipeline.core.run import PipelineRun\n",
        "from azureml.pipeline.steps import AutoMLStep\n",
        "from azureml.train.automl import AutoMLConfig\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "\n",
        "# Check core SDK version number\n",
        "print(\"Azure SDK version:\", azureml.core.VERSION)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Azure SDK version: 1.19.0\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1609600290161
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Authentication\n",
        "### Local CLI configuration\n",
        "I skipped granting local shell rights because i am using the Azure environment provided by udacity.\n",
        "### Azure Python SDK initialization"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.from_config()\n",
        "# ws = Workspace.get(name=\"quick-starts-ws-128192\") # UPDATE THIS LINE WITH EACH NEW VM INSTANCE!\n",
        "\n",
        "print('Workspace name: ' + ws.name, \n",
        "      'Azure region: ' + ws.location, \n",
        "      'Subscription id: ' + ws.subscription_id, \n",
        "      'Resource group: ' + ws.resource_group, sep = '\\n')\n",
        "\n",
        "# DONT FORGET TO CLICK THE LOGIN LINK!"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing interactive authentication. Please follow the instructions on the terminal.\n",
            "To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code A3G6N96VY to authenticate.\n",
            "You have logged in. Now let us find all the subscriptions to which you have access...\n",
            "Interactive authentication successfully completed.\n",
            "Workspace name: quick-starts-ws-132956\n",
            "Azure region: southcentralus\n",
            "Subscription id: d7f39349-a66b-446e-aba6-0053c2cf1c11\n",
            "Resource group: aml-quickstarts-132956\n"
          ]
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1609600344188
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Experiment' is not defined",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-3-5e3f317bede4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m### Create an Azure Experiment object. An Experiment is a container of trials that represent multiple model runs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mexperiment_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'ml-experiment-1'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mexp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExperiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mws\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexperiment_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m: name 'Experiment' is not defined"
          ]
        }
      ],
      "source": [
        "### Create an Azure Experiment object. An Experiment is a container of trials that represent multiple model runs.\n",
        "experiment_name = 'ml-experiment-1'\n",
        "exp = Experiment(workspace=ws, name=experiment_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# retrieve the `auth_header` which will later be used for authenticating at the API endpoint\r\n",
        "auth_header = InteractiveLoginAuthentication().get_authentication_header()\r\n",
        "auth_header"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 124,
          "data": {
            "text/plain": "{'Authorization': 'Bearer eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsIng1dCI6IjVPZjlQNUY5Z0NDd0NtRjJCT0hIeEREUS1EayIsImtpZCI6IjVPZjlQNUY5Z0NDd0NtRjJCT0hIeEREUS1EayJ9.eyJhdWQiOiJodHRwczovL21hbmFnZW1lbnQuY29yZS53aW5kb3dzLm5ldC8iLCJpc3MiOiJodHRwczovL3N0cy53aW5kb3dzLm5ldC82NjBiMzM5OC1iODBlLTQ5ZDItYmM1Yi1hYzFkYzkzYjUyNTQvIiwiaWF0IjoxNjA5NjA2NjU0LCJuYmYiOjE2MDk2MDY2NTQsImV4cCI6MTYwOTYxMDU1NCwiYWNyIjoiMSIsImFpbyI6IkUySmdZRkRiVjJyVStYV040MHVWbVFyMkorVG1ISThLNnp2OXdmWnUyNTNJVDZFR2w2MEEiLCJhbXIiOlsicHdkIl0sImFwcGlkIjoiMDRiMDc3OTUtOGRkYi00NjFhLWJiZWUtMDJmOWUxYmY3YjQ2IiwiYXBwaWRhY3IiOiIwIiwiZmFtaWx5X25hbWUiOiIxMzI5NTYiLCJnaXZlbl9uYW1lIjoiT0RMX1VzZXIiLCJpcGFkZHIiOiIxMy42Ni44NC4yMjQiLCJuYW1lIjoiT0RMX1VzZXIgMTMyOTU2Iiwib2lkIjoiYTI2NGQwMDUtODM5NC00NTdmLTgzZTUtMDU3M2VjNzkwM2VhIiwicHVpZCI6IjEwMDMyMDAxMDg3NzZFMzEiLCJyaCI6IjAuQUFBQW1ETUxaZzY0MGttOFc2d2R5VHRTVkpWM3NBVGJqUnBHdS00Qy1lR19lMFpTQUVZLiIsInNjcCI6InVzZXJfaW1wZXJzb25hdGlvbiIsInN1YiI6Ik4yMnI3VjJpV3ZKdEZTWEtNMkxZX0ZDcVkzTGRCUjhNSTRVOWhUaG9DSjQiLCJ0aWQiOiI2NjBiMzM5OC1iODBlLTQ5ZDItYmM1Yi1hYzFkYzkzYjUyNTQiLCJ1bmlxdWVfbmFtZSI6Im9kbF91c2VyXzEzMjk1NkB1ZGFjaXR5bGFicy5vbm1pY3Jvc29mdC5jb20iLCJ1cG4iOiJvZGxfdXNlcl8xMzI5NTZAdWRhY2l0eWxhYnMub25taWNyb3NvZnQuY29tIiwidXRpIjoiMHpqdUd2alREVXVpbUpPU1NvT1hBQSIsInZlciI6IjEuMCIsIndpZHMiOlsiYjc5ZmJmNGQtM2VmOS00Njg5LTgxNDMtNzZiMTk0ZTg1NTA5Il0sInhtc190Y2R0IjoxNTg4MzU3ODAzfQ.F9EcN8fnOor8FBfJHYctUqAq1pf8D2FMnL8YJtW8WQ454Mnr3kVaSQwsn4351kv20FirVECpHYd9cITRT5CrOsiH_GMaNvUPieasPUvKdOVhebd7gmD_3AbjkAyrRRRvlfIaf3NaBCtK1vsiggDki7gQaQYSCXpGnwu0aN97m_jPxlp2ve42b6dGfExRME8uzdLqMdFRcidWW0RZ-SLoCFkyycUb5Qst41l380FmcodmwkmReW6RXNmsH8sB0qk5xPwJeJKz2JRV2Kc2EQuaTvKAWWUiHU3GOuZtZyyCutwhl0mH4SGDxnIiaNndnzFHxAQ2SZu7R6X4fDQHQtEXjQ'}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 124,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1609609864860
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Automated ML Experiment\n",
        "In this step we will create an AutoML experiment to find a best model for classifying our dataset.\n",
        "We will later do the same with a pipeline.\n",
        "\n",
        "### Prepare Dataset\n",
        "\n",
        "Before doing AutoML, we need to prepare the dataset. For this, we will be using the cleaning function from the first project."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Try to load the dataset from the Workspace. Otherwise, create it from the file\n",
        "found = False\n",
        "ds_key = \"Bank-marketing\"\n",
        "\n",
        "if ds_key in ws.datasets.keys(): \n",
        "        found = True\n",
        "        ds = ws.datasets[ds_key] \n",
        "\n",
        "if not found:\n",
        "        # Create AML Dataset and register it into Workspace\n",
        "        # Create TabularDataset using TabularDatasetFactory\n",
        "        # https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.data.dataset_factory.tabulardatasetfactory?view=azure-ml-py  \n",
        "        # i download and import the _train.csv, so no further splitting is necessary\n",
        "        example_data = 'https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv'\n",
        "        ds = TabularDatasetFactory.from_delimited_files(path=dataset_path)  \n",
        "        #Register Dataset in Workspace\n",
        "        ds = ds.register(workspace=ws,\n",
        "                        name=ds_key,\n",
        "                        description=\"Bank Marketing DataSet for Udacity Course 2\")\n"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1609600344746
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data cleaning like in project-01\n",
        "\n",
        "def clean_data(data):\n",
        "    # Dict for cleaning data\n",
        "    months = {\"jan\":1, \"feb\":2, \"mar\":3, \"apr\":4, \"may\":5, \"jun\":6, \"jul\":7, \"aug\":8, \"sep\":9, \"oct\":10, \"nov\":11, \"dec\":12}\n",
        "    weekdays = {\"mon\":1, \"tue\":2, \"wed\":3, \"thu\":4, \"fri\":5, \"sat\":6, \"sun\":7}\n",
        "\n",
        "    # Clean and one hot encode data\n",
        "    x_df = data.to_pandas_dataframe().dropna()\n",
        "    jobs = pd.get_dummies(x_df.job, prefix=\"job\")\n",
        "    x_df.drop(\"job\", inplace=True, axis=1)\n",
        "    x_df = x_df.join(jobs)\n",
        "    x_df[\"marital\"] = x_df.marital.apply(lambda s: 1 if s == \"married\" else 0)\n",
        "    x_df[\"default\"] = x_df.default.apply(lambda s: 1 if s == \"yes\" else 0)\n",
        "    x_df[\"housing\"] = x_df.housing.apply(lambda s: 1 if s == \"yes\" else 0)\n",
        "    x_df[\"loan\"] = x_df.loan.apply(lambda s: 1 if s == \"yes\" else 0)\n",
        "    contact = pd.get_dummies(x_df.contact, prefix=\"contact\")\n",
        "    x_df.drop(\"contact\", inplace=True, axis=1)\n",
        "    x_df = x_df.join(contact)\n",
        "    education = pd.get_dummies(x_df.education, prefix=\"education\")\n",
        "    x_df.drop(\"education\", inplace=True, axis=1)\n",
        "    x_df = x_df.join(education)\n",
        "    x_df[\"month\"] = x_df.month.map(months)\n",
        "    x_df[\"day_of_week\"] = x_df.day_of_week.map(weekdays)\n",
        "    x_df[\"poutcome\"] = x_df.poutcome.apply(lambda s: 1 if s == \"success\" else 0)\n",
        "\n",
        "    y_df = x_df.pop(\"y\").apply(lambda s: 1 if s == \"yes\" else 0)\n",
        "\n",
        "    return x_df, y_df\n",
        "\n",
        "found_clean = False\n",
        "if ds_key +\"-clean\" in ws.datasets.keys(): \n",
        "        found_clean = True\n",
        "        ds_clean = ws.datasets[ds_key +\"-clean\"] \n",
        "\n",
        "if not found_clean:\n",
        "    # Use the clean_data function to clean your data.\n",
        "    x, y = clean_data(ds)\n",
        "    df_clean = x.join(y)\n",
        "\n",
        "    #Register cleaned Dataset in Workspace\n",
        "    ds_clean = TabularDatasetFactory.register_pandas_dataframe(df_clean, ws.get_default_datastore(), ds_key +\"-clean\",\n",
        "                                                                description=\"Cleaned Bank Marketing DataSet for Udacity Course 2\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Method register_pandas_dataframe: This is an experimental method, and may change at any time.<br/>For more information, see https://aka.ms/azuremlexperimental.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validating arguments.\n",
            "Arguments validated.\n",
            "Successfully obtained datastore reference and path.\n",
            "Uploading file to managed-dataset/e7dbda71-a120-496c-a124-96038b47fcec/\n",
            "Successfully uploaded file to datastore.\n",
            "Creating and registering a new dataset.\n",
            "Successfully created and registered a new dataset.\n"
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1609600354854
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_clean = ds_clean.to_pandas_dataframe()\n",
        "df_clean.describe()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "                age       marital       default       housing          loan  \\\ncount  32950.000000  32950.000000  32950.000000  32950.000000  32950.000000   \nmean      40.040212      0.605948      0.000091      0.522974      0.151806   \nstd       10.432313      0.488653      0.009542      0.499479      0.358838   \nmin       17.000000      0.000000      0.000000      0.000000      0.000000   \n25%       32.000000      0.000000      0.000000      0.000000      0.000000   \n50%       38.000000      1.000000      0.000000      1.000000      0.000000   \n75%       47.000000      1.000000      0.000000      1.000000      0.000000   \nmax       98.000000      1.000000      1.000000      1.000000      1.000000   \n\n              month   day_of_week      duration      campaign         pdays  \\\ncount  32950.000000  32950.000000  32950.000000  32950.000000  32950.000000   \nmean       6.605281      2.980789    257.335205      2.561730    962.174780   \nstd        2.041099      1.411580    257.331700      2.763646    187.646785   \nmin        3.000000      1.000000      0.000000      1.000000      0.000000   \n25%        5.000000      2.000000    102.000000      1.000000    999.000000   \n50%        6.000000      3.000000    179.000000      2.000000    999.000000   \n75%        8.000000      4.000000    318.000000      3.000000    999.000000   \nmax       12.000000      5.000000   4918.000000     56.000000    999.000000   \n\n       ...  contact_telephone  education_basic_4y  education_basic_6y  \\\ncount  ...       32950.000000        32950.000000        32950.000000   \nmean   ...           0.364310            0.101153            0.056055   \nstd    ...           0.481243            0.301536            0.230031   \nmin    ...           0.000000            0.000000            0.000000   \n25%    ...           0.000000            0.000000            0.000000   \n50%    ...           0.000000            0.000000            0.000000   \n75%    ...           1.000000            0.000000            0.000000   \nmax    ...           1.000000            1.000000            1.000000   \n\n       education_basic_9y  education_high_school  education_illiterate  \\\ncount        32950.000000           32950.000000          32950.000000   \nmean             0.147496               0.229226              0.000455   \nstd              0.354605               0.420341              0.021332   \nmin              0.000000               0.000000              0.000000   \n25%              0.000000               0.000000              0.000000   \n50%              0.000000               0.000000              0.000000   \n75%              0.000000               0.000000              0.000000   \nmax              1.000000               1.000000              1.000000   \n\n       education_professional_course  education_university_degree  \\\ncount                   32950.000000                 32950.000000   \nmean                        0.128346                     0.294901   \nstd                         0.334480                     0.456005   \nmin                         0.000000                     0.000000   \n25%                         0.000000                     0.000000   \n50%                         0.000000                     0.000000   \n75%                         0.000000                     1.000000   \nmax                         1.000000                     1.000000   \n\n       education_unknown             y  \ncount       32950.000000  32950.000000  \nmean            0.042367      0.112049  \nstd             0.201429      0.315431  \nmin             0.000000      0.000000  \n25%             0.000000      0.000000  \n50%             0.000000      0.000000  \n75%             0.000000      0.000000  \nmax             1.000000      1.000000  \n\n[8 rows x 40 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>marital</th>\n      <th>default</th>\n      <th>housing</th>\n      <th>loan</th>\n      <th>month</th>\n      <th>day_of_week</th>\n      <th>duration</th>\n      <th>campaign</th>\n      <th>pdays</th>\n      <th>...</th>\n      <th>contact_telephone</th>\n      <th>education_basic_4y</th>\n      <th>education_basic_6y</th>\n      <th>education_basic_9y</th>\n      <th>education_high_school</th>\n      <th>education_illiterate</th>\n      <th>education_professional_course</th>\n      <th>education_university_degree</th>\n      <th>education_unknown</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>32950.000000</td>\n      <td>32950.000000</td>\n      <td>32950.000000</td>\n      <td>32950.000000</td>\n      <td>32950.000000</td>\n      <td>32950.000000</td>\n      <td>32950.000000</td>\n      <td>32950.000000</td>\n      <td>32950.000000</td>\n      <td>32950.000000</td>\n      <td>...</td>\n      <td>32950.000000</td>\n      <td>32950.000000</td>\n      <td>32950.000000</td>\n      <td>32950.000000</td>\n      <td>32950.000000</td>\n      <td>32950.000000</td>\n      <td>32950.000000</td>\n      <td>32950.000000</td>\n      <td>32950.000000</td>\n      <td>32950.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>40.040212</td>\n      <td>0.605948</td>\n      <td>0.000091</td>\n      <td>0.522974</td>\n      <td>0.151806</td>\n      <td>6.605281</td>\n      <td>2.980789</td>\n      <td>257.335205</td>\n      <td>2.561730</td>\n      <td>962.174780</td>\n      <td>...</td>\n      <td>0.364310</td>\n      <td>0.101153</td>\n      <td>0.056055</td>\n      <td>0.147496</td>\n      <td>0.229226</td>\n      <td>0.000455</td>\n      <td>0.128346</td>\n      <td>0.294901</td>\n      <td>0.042367</td>\n      <td>0.112049</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>10.432313</td>\n      <td>0.488653</td>\n      <td>0.009542</td>\n      <td>0.499479</td>\n      <td>0.358838</td>\n      <td>2.041099</td>\n      <td>1.411580</td>\n      <td>257.331700</td>\n      <td>2.763646</td>\n      <td>187.646785</td>\n      <td>...</td>\n      <td>0.481243</td>\n      <td>0.301536</td>\n      <td>0.230031</td>\n      <td>0.354605</td>\n      <td>0.420341</td>\n      <td>0.021332</td>\n      <td>0.334480</td>\n      <td>0.456005</td>\n      <td>0.201429</td>\n      <td>0.315431</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>17.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>32.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>5.000000</td>\n      <td>2.000000</td>\n      <td>102.000000</td>\n      <td>1.000000</td>\n      <td>999.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>38.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>6.000000</td>\n      <td>3.000000</td>\n      <td>179.000000</td>\n      <td>2.000000</td>\n      <td>999.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>47.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>8.000000</td>\n      <td>4.000000</td>\n      <td>318.000000</td>\n      <td>3.000000</td>\n      <td>999.000000</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>98.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>12.000000</td>\n      <td>5.000000</td>\n      <td>4918.000000</td>\n      <td>56.000000</td>\n      <td>999.000000</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 40 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1609600355234
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean.head(5)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "   age  marital  default  housing  loan  month  day_of_week  duration  \\\n0   57        1        0        0     1      5            1       371   \n1   55        1        0        1     0      5            4       285   \n2   33        1        0        0     0      5            5        52   \n3   36        1        0        0     0      6            5       355   \n4   27        1        0        1     0      7            5       189   \n\n   campaign  pdays  ...  contact_telephone  education_basic_4y  \\\n0         1    999  ...                  0                   0   \n1         2    999  ...                  1                   0   \n2         1    999  ...                  0                   0   \n3         4    999  ...                  1                   0   \n4         2    999  ...                  0                   0   \n\n   education_basic_6y  education_basic_9y  education_high_school  \\\n0                   0                   0                      1   \n1                   0                   0                      0   \n2                   0                   1                      0   \n3                   0                   0                      1   \n4                   0                   0                      1   \n\n   education_illiterate  education_professional_course  \\\n0                     0                              0   \n1                     0                              0   \n2                     0                              0   \n3                     0                              0   \n4                     0                              0   \n\n   education_university_degree  education_unknown  y  \n0                            0                  0  0  \n1                            0                  1  0  \n2                            0                  0  0  \n3                            0                  0  0  \n4                            0                  0  0  \n\n[5 rows x 40 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>marital</th>\n      <th>default</th>\n      <th>housing</th>\n      <th>loan</th>\n      <th>month</th>\n      <th>day_of_week</th>\n      <th>duration</th>\n      <th>campaign</th>\n      <th>pdays</th>\n      <th>...</th>\n      <th>contact_telephone</th>\n      <th>education_basic_4y</th>\n      <th>education_basic_6y</th>\n      <th>education_basic_9y</th>\n      <th>education_high_school</th>\n      <th>education_illiterate</th>\n      <th>education_professional_course</th>\n      <th>education_university_degree</th>\n      <th>education_unknown</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>57</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>5</td>\n      <td>1</td>\n      <td>371</td>\n      <td>1</td>\n      <td>999</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>55</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>5</td>\n      <td>4</td>\n      <td>285</td>\n      <td>2</td>\n      <td>999</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>33</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>5</td>\n      <td>52</td>\n      <td>1</td>\n      <td>999</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>36</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>5</td>\n      <td>355</td>\n      <td>4</td>\n      <td>999</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>27</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7</td>\n      <td>5</td>\n      <td>189</td>\n      <td>2</td>\n      <td>999</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 40 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1609600355336
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Screenshot of “Registered Datasets” in ML Studio showing that Bankmarketing dataset (and the cleaned version) are available:\n",
        "![registered_datasets](images/registered_datasets.jpg)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a compute cluster\n",
        "\n",
        "Create compute cluster \"Standard_DS12_v2\" and min number of nodes = 1\n",
        "([Documentation](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-create-attach-compute-cluster?tabs=python))"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a name for your CPU cluster\n",
        "cpu_cluster_name = \"auto-ml\"\n",
        "\n",
        "# Verify that cluster does not exist already\n",
        "try:\n",
        "    cpu_cluster = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2',# for GPU, use \"STANDARD_NC6\"\n",
        "                                                           #vm_priority = 'lowpriority', # optional\n",
        "                                                           max_nodes=4)\n",
        "    cpu_cluster = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
        "\n",
        "cpu_cluster.wait_for_completion(show_output=True) # , min_node_count = 1, timeout_in_minutes = 10\n",
        "# For a more detailed view of current AmlCompute status, use get_status().\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating\n",
            "Succeeded\n",
            "AmlCompute wait for completion finished\n",
            "\n",
            "Minimum number of nodes requested have been provisioned\n"
          ]
        }
      ],
      "execution_count": 88,
      "metadata": {
        "gather": {
          "logged": 1609605628841
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cpu_cluster.get_status()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 89,
          "data": {
            "text/plain": "<azureml.core.compute.amlcompute.AmlComputeStatus at 0x7fb4f4be7fd0>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 89,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1609605632071
        }
      }
    },
    {
      "source": [
        "### Create an AutoML Experiment"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "automl_config = AutoMLConfig(\n",
        "    compute_target=cpu_cluster,\n",
        "    experiment_timeout_minutes=30,\n",
        "    task=\"classification\",\n",
        "    primary_metric=\"accuracy\",\n",
        "    training_data=ds_clean,\n",
        "    label_column_name=\"y\",\n",
        "    n_cross_validations=3)"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1609600355827
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Submit automl run\n",
        "automl_run = exp.submit(config=automl_config)\n",
        "RunDetails(automl_run).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "automl_run.wait_for_completion()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Deployment\n",
        "After the experiment run completes, a summary of all the models and their metrics are shown, including explanations. The Best Model will be shown in the Details tab. In the Models tab, it will come up first (at the top). Make sure you select the best model for deployment.\n",
        "\n",
        "Deploying the Best Model will allow to interact with the HTTP API service and interact with the model by sending data over POST requests.\n",
        "\n",
        "### Select the best model for deployment"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Retrieve and save your best automl model.\n",
        "# Get your best run and save the model from that run.\n",
        "#best_run = hyperdrive_run.get_best_run_by_primary_metric()\n",
        "best_automl_run, best_automl_model = automl_run.get_output()\n",
        "best_automl_run_metrics = best_automl_run.get_metrics()\n",
        "\n",
        "#parameter_values = best_automl_run.get_details()['runDefinition']['arguments']\n",
        "\n",
        "# examine metrics of best model\n",
        "\n",
        "#print('Best Run Id: ', best_automl_run.id)\n",
        "print('Accuracy:', best_automl_run_metrics['accuracy'])\n",
        "print('Metrics:', best_automl_run_metrics)\n",
        "#print('Inverse of regularization strength:',parameter_values[1])\n",
        "#print('Maximum number of iterations to converge:',parameter_values[3])\n",
        "print(\"Model\",best_automl_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# save best model\n",
        "print(\"Files\", best_automl_run.get_file_names())\n",
        "# https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.run(class)?view=azure-ml-py#download-file-name--output-file-path-none---validate-checksum-false-\n",
        "best_automl_run.download_file('outputs/model.pkl', output_file_path='best_automl_model.joblib')\n",
        "\n",
        "# register best model\n",
        "best_automl_model_reg = best_automl_run.register_model(model_name='best_automl_model', model_path='outputs/model.pkl', \n",
        "                            model_framework=Model.Framework.SCIKITLEARN,\n",
        "                            description = \"Best Model to classify the Bank Marketing Dataset\",\n",
        "                            model_framework_version=sklearn.__version__,\n",
        "                            resource_configuration=ResourceConfiguration(cpu=1, memory_in_gb=0.5))"
      ]
    },
    {
      "source": [
        "#### Deployment of the best Model\n",
        "\n",
        "Deploy the model using Azure Container Instance (ACI) and enable \"Authentication\"\n",
        "\n",
        "(Documentation for [Deploy Model](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-and-where?tabs=python#deploy-your-model),\n",
        "[model.deploy()](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.model.model?preserve-view=true&view=azure-ml-py#deploy-workspace--name--models--inference-config-none--deployment-config-none--deployment-target-none--overwrite-false-), [ONXX](https://docs.microsoft.com/en-us/python/api/azureml-automl-runtime/azureml.automl.runtime.onnx_convert.onnx_converter.onnxconverter?view=azure-ml-py), [Register Model](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.run.run?view=azure-ml-py#register-model-model-name--model-path-none--tags-none--properties-none--model-framework-none--model-framework-version-none--description-none--datasets-none--sample-input-dataset-none--sample-output-dataset-none--resource-configuration-none----kwargs-), [No Code](https://docs.microsoft.com/de-de/azure/machine-learning/how-to-deploy-no-code-deployment))"
      ],
      "cell_type": "markdown",
      "metadata": {
        "gather": {
          "logged": 1609603311954
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_automl_model_pub = Model.deploy(ws, 'my-model-service', [best_automl_model_reg])\n",
        "best_automl_model_pub.wait_for_deployment(show_output = True)\n",
        "print(best_automl_model_pub.state)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Enable logging / Application Insights\n",
        "Now that the Best Model is deployed, enable Application Insights and retrieve logs. Although this is configurable at deploy time with a check-box, it is useful to be able to run code that will enable it for you.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure <code>az</code> is installed, as well as the Python SDK for Azure\n",
        "# Create a new virtual environment with Python3\n",
        "# Write and run code to enable Application Insights\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: Take a screenshot showing that \"Application Insights\" is enabled in the Details tab of the endpoint.\r\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from opencensus.ext.azure.log_exporter import AzureLogHandler\n",
        "import logging\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "logger.setLevel(logging.DEBUG)\n",
        "logger.addHandler(logging.StreamHandler())\n",
        "\n",
        "# Assumes the environment variable APPLICATIONINSIGHTS_CONNECTION_STRING is already set\n",
        "logger.addHandler(AzureLogHandler())\n",
        "logger.warning(\"I will be sent to Application Insights\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Use this provided code <code>logs.py</code> to view the logs\n",
        "\n",
        "\n",
        "# Requires the config to be downloaded first to the current working directory\n",
        "# ws = Workspace.from_config()\n",
        "\n",
        "# Set with the deployment name\n",
        "# load existing web service\n",
        "service = Webservice(name=published_model.name, workspace=ws)\n",
        "logs = service.get_logs()\n",
        "\n",
        "for line in logs.split('\\n'):\n",
        "    print(line)\n"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "WebserviceException",
          "evalue": "WebserviceException:\n\tMessage: WebserviceNotFound: Webservice with name bankmarketing_pipeline not found in provided workspace\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"WebserviceNotFound: Webservice with name bankmarketing_pipeline not found in provided workspace\"\n    }\n}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mWebserviceException\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-86-9d5ea2a22335>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Set with the deployment name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# load existing web service\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mservice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWebservice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpublished_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/webservice/webservice.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, workspace, name)\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                 raise WebserviceException('WebserviceNotFound: Webservice with name {} not found in provided '\n\u001b[0;32m--> 215\u001b[0;31m                                           'workspace'.format(name))\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWebservice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mWebserviceException\u001b[0m: WebserviceException:\n\tMessage: WebserviceNotFound: Webservice with name bankmarketing_pipeline not found in provided workspace\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"WebserviceNotFound: Webservice with name bankmarketing_pipeline not found in provided workspace\"\n    }\n}"
          ]
        }
      ],
      "execution_count": 86,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: Take a screenshot showing logs by running the provided logs.py script *above"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Swagger Documentation\n",
        "In this step, you will consume the deployed model using Swagger.\n",
        "\n",
        "Azure provides a Swagger JSON file for deployed models. Head to the Endpoints section, and find your deployed model there, it should be the first one on the list.\n",
        "\n",
        "A few things you need to pay attention to:\n",
        "\n",
        "swagger.sh will download the latest Swagger container, and it will run it on port 80. If you don't have permissions for port 80 on your computer, update the script to a higher number (above 9000 is a good idea).\n",
        "\n",
        "serve.py will start a Python server on port 8000. This script needs to be right next to the downloaded swagger.json file. NOTE: this will not work if swagger.json is not on the same directory.\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "question> we deployed a pipeline not a model, i cant find swagger json file"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the swagger.json file\n",
        "# Interact with the swagger instance running with the documentation for the HTTP API of the model.\n",
        "# Display the contents of the API for the model"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the swagger.sh and serve the json file\n",
        "\n",
        "def serve_swaggerjson():\n",
        "    os.system('python3 swagger/serve.py 8000 > swagger/serve_log.txt 2>&1 & ')\n",
        "\n",
        "def run_swaggerui():\n",
        "    os.system('swagger/swagger.sh > swagger/run_log.txt 2>&1 & ')\n",
        "\n",
        "\n",
        "threading.Thread(target=serve_swaggerjson).start()\n",
        "threading.Thread(target=run_swaggerui).start()"
      ],
      "outputs": [],
      "execution_count": 106,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1609608084882
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: Take a screenshot showing that swagger runs on localhost showing the HTTP API methods and responses for the model\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Consume model endpoints\n",
        "Once the model is deployed, use the endpoint.py script provided to interact with the trained model. In this step, you need to run the script, modifying both the scoring_uri and the key to match the key for your service and the URI that was generated after deployment.\n",
        "\n",
        "Hint: This URI can be found in the Details tab, above the Swagger URI.\n",
        "\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# URL for the web service, should be similar to:\n",
        "# 'http://8530a665-66f3-49c8-a953-b82a2d312917.eastus.azurecontainer.io/score' #URI that was generated after deployment\n",
        "scoring_uri = published_model.endpoint # ''\n",
        "# If the service is authenticated, set the key or token # key for your service\n",
        "key = auth_header # ''\n",
        "\n",
        "# Two sets of data to score, so we get two results back\n",
        "data = {\"data\":\n",
        "        [\n",
        "          {\n",
        "            \"age\": 17,\n",
        "            \"campaign\": 1,\n",
        "            \"cons.conf.idx\": -46.2,\n",
        "            \"cons.price.idx\": 92.893,\n",
        "            \"contact\": \"cellular\",\n",
        "            \"day_of_week\": \"mon\",\n",
        "            \"default\": \"no\",\n",
        "            \"duration\": 971,\n",
        "            \"education\": \"university.degree\",\n",
        "            \"emp.var.rate\": -1.8,\n",
        "            \"euribor3m\": 1.299,\n",
        "            \"housing\": \"yes\",\n",
        "            \"job\": \"blue-collar\",\n",
        "            \"loan\": \"yes\",\n",
        "            \"marital\": \"married\",\n",
        "            \"month\": \"may\",\n",
        "            \"nr.employed\": 5099.1,\n",
        "            \"pdays\": 999,\n",
        "            \"poutcome\": \"failure\",\n",
        "            \"previous\": 1\n",
        "          },\n",
        "          {\n",
        "            \"age\": 87,\n",
        "            \"campaign\": 1,\n",
        "            \"cons.conf.idx\": -46.2,\n",
        "            \"cons.price.idx\": 92.893,\n",
        "            \"contact\": \"cellular\",\n",
        "            \"day_of_week\": \"mon\",\n",
        "            \"default\": \"no\",\n",
        "            \"duration\": 471,\n",
        "            \"education\": \"university.degree\",\n",
        "            \"emp.var.rate\": -1.8,\n",
        "            \"euribor3m\": 1.299,\n",
        "            \"housing\": \"yes\",\n",
        "            \"job\": \"blue-collar\",\n",
        "            \"loan\": \"yes\",\n",
        "            \"marital\": \"married\",\n",
        "            \"month\": \"may\",\n",
        "            \"nr.employed\": 5099.1,\n",
        "            \"pdays\": 999,\n",
        "            \"poutcome\": \"failure\",\n",
        "            \"previous\": 1\n",
        "          },\n",
        "      ]\n",
        "    }\n",
        "# Convert to JSON string\n",
        "input_data = json.dumps(data)\n",
        "with open(\"data.json\", \"w\") as _f:\n",
        "    _f.write(input_data)\n",
        "\n",
        "# Set the content type\n",
        "headers = {'Content-Type': 'application/json'}\n",
        "# If authentication is enabled, set the authorization header\n",
        "headers['Authorization'] = f'Bearer {key}'\n",
        "\n",
        "# Make the request and display the response\n",
        "resp = requests.post(scoring_uri, input_data, headers=headers)\n",
        "print(resp.json())\n",
        "\n",
        "# output should be similar to this: {\"result\": [\"yes\", \"no\"]}"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: Take a screenshot showing that the `endpoint.py` script runs against the API producing JSON output from the model."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Create, Publish and consume a pipeline\n",
        "The experiment above already runs inside a pipeline. It therefore does not have to be created again, the pipeline was created in the above steps already.\n",
        "\n",
        "I updated the notebook [aml-pipelines-with-automated-machine-learning-step.ipynb](aml-pipelines-with-automated-machine-learning-step.ipynb) to have the same keys, URI, dataset, cluster, and model names etc. we already created, but i also included all of it's parts inside this notebook so everything can be run using one single notebook.\n",
        "\n",
        "\n",
        "- upload the Jupyter Notebook aml-pipelines-with-automated-machine-learning-step.ipynb to the Azure ML studio\n",
        "- Update all the variables that are noted to match your environment\n",
        "- Make sure a <code>config.json</code> has been downloaded and is available in the current working directory\n",
        "- Run through the cells\n",
        "- Verify the pipeline has been created and shows in Azure ML studio, in the <em>Pipelines</em> section\n",
        "- Verify that the pipeline has been scheduled to run or is running\n",
        "\n",
        "\n",
        "### Create Pipeline"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set parameters for AutoMLConfig\n",
        "# NOTE: DO NOT CHANGE THE experiment_timeout_minutes PARAMETER OR YOUR INSTANCE WILL TIME OUT.\n",
        "# If you wish to run the experiment longer, you will need to run this notebook in your own\n",
        "# Azure tenant, which will incur personal costs.\n",
        "\n",
        "automl_config = AutoMLConfig(compute_target=cpu_cluster,\n",
        "                             task = \"classification\",\n",
        "                             training_data=ds_clean,\n",
        "                             label_column_name=\"y\",   \n",
        "                             path = './pipeline-project',\n",
        "                             enable_early_stopping= True,\n",
        "                             featurization= 'auto',\n",
        "                             debug_log = \"automl_errors.log\",\n",
        "                             experiment_timeout_minutes = 20,\n",
        "                             max_concurrent_iterations = 5,\n",
        "                             # n_cross_validations=3,\n",
        "                             primary_metric = \"AUC_weighted\" #  or \"accuracy\"\n",
        "                            )\n",
        "\n",
        "\n",
        "metrics_output_name = 'metrics_output'\n",
        "metrics_data = PipelineData(name='metrics_data',\n",
        "                           datastore=ws.get_default_datastore(),\n",
        "                           pipeline_output_name=metrics_output_name,\n",
        "                           training_output=TrainingOutput(type='Metrics'))\n",
        "\n",
        "best_model_output_name = 'best_model_output'\n",
        "best_model_data = PipelineData(name='model_data',\n",
        "                           datastore=ws.get_default_datastore(),\n",
        "                           pipeline_output_name=best_model_output_name,\n",
        "                           training_output=TrainingOutput(type='Model'))\n",
        "\n",
        "pipeline = Pipeline(\n",
        "    description=\"pipeline_with_automlstep\",\n",
        "    workspace=ws,    \n",
        "    steps=[AutoMLStep(\n",
        "            name='automl_module',\n",
        "            automl_config=automl_config,\n",
        "            outputs=[metrics_data, best_model_data],\n",
        "            allow_reuse=True)\n",
        "          ])\n",
        "\n",
        "pipeline_run = exp.submit(pipeline) #TODO: compute_target = cpu_cluster #config=automl_config\n",
        "\n",
        "# Submit automl run\n",
        "RunDetails(pipeline_run).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipeline_run.wait_for_completion()"
      ]
    },
    {
      "source": [
        "Screenshot showing that the experiment is shown as completed:\n",
        "![experiment overview](images/experiments_overview.jpg)\n",
        "![completed run](images/completed_run.jpg)\n",
        "([picture of second try](images/experiments_overview_2.jpg))"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "### Retreive best Model for the Pipeline Run\n",
        "(Documentation for the [PipelineRun Class](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-core/azureml.pipeline.core.pipelinerun?view=azure-ml-py))\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#download pipeline output about metrics (of child runs) and examine them\n",
        "metrics_portref = pipeline_run.get_pipeline_output(metrics_output_name)\n",
        "num_file_downloaded = metrics_portref.download('.', show_progress=True)\n",
        "\n",
        "with open(metrics_portref._path_on_datastore) as f:\n",
        "    metrics = f.read()\n",
        "    \n",
        "pd.DataFrame(json.loads(metrics)).T.applymap(lambda x: np.round(x[0],8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# download pipeline output about the best model and examine it\n",
        "best_model_portref = pipeline_run.get_pipeline_output(best_model_output_name)\n",
        "num_file_downloaded = best_model_portref.download('.', show_progress=True)\n",
        "\n",
        "with open(best_model_portref._path_on_datastore, \"rb\" ) as f:\n",
        "    best_model = pickle.load(f)\n",
        "\n",
        "# show best model\n",
        "best_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_model.steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "You can see details of the best model _VotingEnsemble_ above, following is a screenshot of the list of AutoML models:\n",
        "![automl model list](images/generated_models.jpg)\n",
        "(Further screenshots of [best model](images/best_model.jpg), [best model steps](images/best_model_steps.jpg))"
      ]
    },
    {
      "source": [
        "### Optional: Quick testing of the best model\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load test data\n",
        "ds_test = TabularDatasetFactory.from_delimited_files(path='https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_test.csv')\n",
        "\n",
        "x, y = clean_data(ds_test)\n",
        "\n",
        "# Fix differently named columns in test dataset\n",
        "x.columns = [c.replace(\".\",\"_\") for c in x.columns]\n",
        "\n",
        "df_test = x.join(y)\n",
        "df_test = df_test[pd.notnull(df_test['y'])]\n",
        "\n",
        "y_test = df_test['y']\n",
        "X_test = df_test.drop(['y'], axis=1)\n",
        "\n",
        "# predict\n",
        "y_test_pred = best_model.predict(X_test)\n",
        "\n",
        "# Visualize via confusion matrix\n",
        "pd.DataFrame(confusion_matrix(y_test, y_test_pred)).style.background_gradient(cmap='Blues', low=0, high=0.9)"
      ]
    },
    {
      "source": [
        "### Optional: Save, Register and Deploy the Model of Pipeline"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# save best model to disk\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "joblib.dump(best_model, 'outputs/best_model.joblib')\n",
        "\n",
        "# register the model we just saved\n",
        "registered_model = Model.register(workspace = ws,\n",
        "                           model_name='reg-bankmarketing-model', \n",
        "                           model_path='outputs/best_model.joblib',\n",
        "                           model_framework=Model.Framework.SCIKITLEARN,\n",
        "                           description = \"Best Model to classify the Bank Marketing Dataset\",\n",
        "                           model_framework_version=sklearn.__version__,\n",
        "                           resource_configuration=ResourceConfiguration(cpu=1, memory_in_gb=0.5))\n",
        "\n",
        "# deploy the model we just registered\n",
        "# TODO: left out because nobody found a solution for the crashing container problem\n",
        "# https://knowledge.udacity.com/questions/439802\n",
        "# published_model = Model.deploy(ws, \"pub-bankmarketing-model\", [registered_model], deployment_config=LocalWebservice.deploy_configuration(port=8890))\n",
        "# published_model.wait_for_deployment(show_output = True)\n",
        "# print(published_model.state)"
      ]
    },
    {
      "source": [
        "### Deploy Pipeline\n",
        "Deploying the pipeline enables us to trigger a pipeline training run using an API call.\n",
        "([Documentation](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-pipelines))\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "published_pipeline = pipeline_run.publish_pipeline(name=\"bankmarketing_pipeline\", description=\"Training bankmarketing pipeline\", version=\"1.0\")\n",
        "published_pipeline"
      ]
    },
    {
      "source": [
        "Screenshot of the deployed pipeline:\n",
        "![deployed pipeline endpoint](images/pipeline_endpoint.jpg)\n",
        "\n",
        "### Consume Pipeline\n",
        "Get the REST url from the endpoint property of the published pipeline object. You can also find the REST url in your workspace in the portal. Build an HTTP POST request to the endpoint, specifying your authentication header. Additionally, add a JSON payload object with the experiment name and the batch size parameter. As a reminder, the process_count_per_node is passed through to ParallelRunStep because you defined it is defined as a PipelineParameter object in the step configuration.\n",
        "\n",
        "Make the request to trigger the run. Access the Id key from the response dict to get the value of the run id."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "rest_endpoint = published_pipeline.endpoint\n",
        "response = requests.post(rest_endpoint, \n",
        "                         headers=auth_header, \n",
        "                         json={\"ExperimentName\": \"pipeline-rest-endpoint\"}\n",
        "                        )\n",
        "try:\n",
        "    response.raise_for_status()\n",
        "except Exception:    \n",
        "    raise Exception(\"Received bad response from the endpoint: {}\\n\"\n",
        "                    \"Response Code: {}\\n\"\n",
        "                    \"Headers: {}\\n\"\n",
        "                    \"Content: {}\".format(rest_endpoint, response.status_code, response.headers, response.content))\n",
        "\n",
        "run_id = response.json().get('Id')\n",
        "print('Submitted pipeline run: ', run_id)\n",
        "\n",
        "# Use run id to monitor status of new run. This will take 10-15 min, looks similar to previous pipeline run, so you can skip watching full output.\n",
        "published_pipeline_run = PipelineRun(ws.experiments[\"pipeline-rest-endpoint\"], run_id)\n",
        "RunDetails(published_pipeline_run).show()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submitted pipeline run:  550c659e-bf03-4f36-a53b-bcb2b3645550\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', …",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d64f4b68b11143b48d629aa5673681aa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/pipeline-rest-endpoint/runs/550c659e-bf03-4f36-a53b-bcb2b3645550?wsid=/subscriptions/d7f39349-a66b-446e-aba6-0053c2cf1c11/resourcegroups/aml-quickstarts-132956/workspaces/quick-starts-ws-132956\", \"run_id\": \"550c659e-bf03-4f36-a53b-bcb2b3645550\", \"run_properties\": {\"run_id\": \"550c659e-bf03-4f36-a53b-bcb2b3645550\", \"created_utc\": \"2021-01-02T16:41:19.41454Z\", \"properties\": {\"azureml.runsource\": \"azureml.PipelineRun\", \"runSource\": \"Unavailable\", \"runType\": \"HTTP\", \"azureml.parameters\": \"{}\", \"azureml.pipelineid\": \"b600d816-9f74-4421-9a8c-80c9c66b9fe1\"}, \"tags\": {\"azureml.pipelineid\": \"b600d816-9f74-4421-9a8c-80c9c66b9fe1\", \"azureml.pipelineComponent\": \"pipelinerun\"}, \"end_time_utc\": \"2021-01-02T17:07:32.81689Z\", \"status\": \"Completed\", \"log_files\": {\"logs/azureml/executionlogs.txt\": \"https://mlstrg132956.blob.core.windows.net/azureml/ExperimentRun/dcid.550c659e-bf03-4f36-a53b-bcb2b3645550/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=yIMgEuQHZp0Fk5Qq68FkRduXzPqWuwn8bhHNwPj8Rms%3D&st=2021-01-02T17%3A31%3A56Z&se=2021-01-03T01%3A41%3A56Z&sp=r\", \"logs/azureml/stderrlogs.txt\": \"https://mlstrg132956.blob.core.windows.net/azureml/ExperimentRun/dcid.550c659e-bf03-4f36-a53b-bcb2b3645550/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=nGx%2BaN12kCobP%2BS9Dp%2FSVPgNUsiT0atEVSC2hOjnxXM%3D&st=2021-01-02T17%3A31%3A56Z&se=2021-01-03T01%3A41%3A56Z&sp=r\", \"logs/azureml/stdoutlogs.txt\": \"https://mlstrg132956.blob.core.windows.net/azureml/ExperimentRun/dcid.550c659e-bf03-4f36-a53b-bcb2b3645550/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=XUeASs%2FTF8Mdt3PZpmtb6pfbE3GDbSpjAHQmiYMS%2B7c%3D&st=2021-01-02T17%3A31%3A56Z&se=2021-01-03T01%3A41%3A56Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/executionlogs.txt\", \"logs/azureml/stderrlogs.txt\", \"logs/azureml/stdoutlogs.txt\"]], \"run_duration\": \"0:26:13\"}, \"child_runs\": [{\"run_id\": \"\", \"name\": \"automl_module\", \"status\": \"NotStarted\", \"start_time\": \"\", \"created_time\": \"\", \"end_time\": \"\", \"duration\": \"\"}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2021-01-02 16:41:27Z] Submitting 1 runs, first five are: 9e9f8b5e:199ca3c3-1449-4f53-b1bf-82dabc291cf2\\n[2021-01-02 17:07:31Z] Completing processing run id 199ca3c3-1449-4f53-b1bf-82dabc291cf2.\\n\\nRun is completed.\", \"graph\": {\"datasource_nodes\": {\"1c1b631b\": {\"node_id\": \"1c1b631b\", \"name\": \"Bank-marketing-clean\"}}, \"module_nodes\": {\"9e9f8b5e\": {\"node_id\": \"9e9f8b5e\", \"name\": \"automl_module\", \"status\": \"NotStarted\"}}, \"edges\": [{\"source_node_id\": \"1c1b631b\", \"source_node_name\": \"Bank-marketing-clean\", \"source_name\": \"data\", \"target_name\": \"training_data\", \"dst_node_id\": \"9e9f8b5e\", \"dst_node_name\": \"automl_module\"}], \"child_runs\": [{\"run_id\": \"\", \"name\": \"automl_module\", \"status\": \"NotStarted\", \"start_time\": \"\", \"created_time\": \"\", \"end_time\": \"\", \"duration\": \"\"}]}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.19.0\"}, \"loading\": false}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 90,
      "metadata": {
        "gather": {
          "logged": 1609605681368
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "published_pipeline_run.wait_for_completion()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PipelineRunId: 550c659e-bf03-4f36-a53b-bcb2b3645550\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/pipeline-rest-endpoint/runs/550c659e-bf03-4f36-a53b-bcb2b3645550?wsid=/subscriptions/d7f39349-a66b-446e-aba6-0053c2cf1c11/resourcegroups/aml-quickstarts-132956/workspaces/quick-starts-ws-132956\n",
            "\n",
            "PipelineRun Execution Summary\n",
            "==============================\n",
            "PipelineRun Status: Finished\n",
            "{'runId': '550c659e-bf03-4f36-a53b-bcb2b3645550', 'status': 'Completed', 'startTimeUtc': '2021-01-02T16:41:21.826092Z', 'endTimeUtc': '2021-01-02T17:07:32.81689Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'Unavailable', 'runType': 'HTTP', 'azureml.parameters': '{}', 'azureml.pipelineid': 'b600d816-9f74-4421-9a8c-80c9c66b9fe1'}, 'inputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://mlstrg132956.blob.core.windows.net/azureml/ExperimentRun/dcid.550c659e-bf03-4f36-a53b-bcb2b3645550/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=sBioWumsSBWeIBSf1SlcmL9b8dnB5OywrQEhEAdpZbU%3D&st=2021-01-02T16%3A31%3A46Z&se=2021-01-03T00%3A41%3A46Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mlstrg132956.blob.core.windows.net/azureml/ExperimentRun/dcid.550c659e-bf03-4f36-a53b-bcb2b3645550/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=T37u507SxxJgZrCbZJfVRQ2Ox81Gr0uXRckncuY7xkQ%3D&st=2021-01-02T16%3A31%3A46Z&se=2021-01-03T00%3A41%3A46Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mlstrg132956.blob.core.windows.net/azureml/ExperimentRun/dcid.550c659e-bf03-4f36-a53b-bcb2b3645550/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=Cm5rosE4PTOvxCY65y5Uatl%2FCRd%2BtUkAoa%2FHwAyfBoI%3D&st=2021-01-02T16%3A31%3A46Z&se=2021-01-03T00%3A41%3A46Z&sp=r'}}\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 120,
          "data": {
            "text/plain": "'Finished'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 120,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1609609256580
        }
      }
    },
    {
      "source": [
        "Screenshot of a successfull pipeline run:\n",
        "![deployed pipeline run endpoint](images/pipeline_run_endpoint.jpg)"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# model and metrics could now be downloaded using the same commands as in the initial training\r\n",
        "#    published_pipeline_run.get_pipeline_output(metrics_output_name)\r\n",
        "# training log etc. is in step run:\r\n",
        "#    list(published_pipeline_run.get_steps())[0]"
      ],
      "outputs": [],
      "execution_count": 123,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1609609620175
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Documentation\n",
        "### Screencast\n",
        "In this project, you need to record a screencast that shows the entire process of the working ML application. The screencast should meet the following criteria: 1-5 min lenght, clear and understandable audio, at least full hd 16:9, readable text.\n",
        "\n",
        "In this project, you need to record a screencast that shows the entire process of the working ML application. The screencast should meet the following criteria:\n",
        "- Working deployed ML model endpoint\n",
        "- deployed pipeline\n",
        "- available automl model\n",
        "- Successful API requests to the endpoint with a JSON payload\n",
        "\n",
        "In case you are unable to provide an audio file, you can include a written description of your script instead of audio, if you prefer. Please include it in your README file.\n",
        "\n",
        "### Screenshots\n",
        "TODO: Please take the following screenshots to show your work:\n",
        "- The pipeline section of Azure ML studio, showing that the pipeline has been created\n",
        "- The pipelines section in Azure ML Studio, showing the Pipeline Endpoint\n",
        "- The Bankmarketing dataset with the AutoML module\n",
        "- The “Published Pipeline overview”, showing a REST endpoint and a status of ACTIVE\n",
        "- In Jupyter Notebook, showing that the “Use RunDetails Widget” shows the step runs\n",
        "- In ML studio showing the scheduled run\n",
        "\n",
        "-------> insert link to youtube here\n",
        "\n",
        "### Readme\n",
        "An important part of your project submissions is a README file that describes the project and documents the main steps. Please use the README.md template provided to you as a start. The README should include the following areas:\n",
        "\n",
        "- project overview\n",
        "- architectural diagram\n",
        "- short description how to improve project in the future\n",
        "- all screenshots mentioned above with short descriptions\n",
        "- link to the screencast video on youtube (or similar)\n",
        "\n",
        "-------> insert link to readme here [README.md](README.md)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Optional: Benchmarking\n",
        "The following is an optional step to benchmark the endpoint using Apache bench. You will not be graded on it but I encourage you to try it out.\n",
        "\n",
        "Make sure you have the Apache Benchmark command-line tool installed and available in your path\n",
        "<p>In the <code>endpoint.py</code>, replace the key and URI again</p>\n",
        "<p>Run <code>endpoint.py</code>. A data.json file should appear</p>\n",
        "<p>Run the <code>benchmark.sh</code> file. The output should look similar to the text below</p>\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# ab -n 10 -v 4 -p data.json -T 'application/json' -H 'Authorization: Bearer REPLACE_WITH_KEY' http://REPLACE_WITH_API_URL/score\r\n",
        "!ab -n 10 -v 4 -p data.json -T 'application/json' -H {'Authorization: ' + auth_header['Authorization'] + published_model.endpoint}"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: Take a screenshot showing that Apache Benchmark (ab) runs against the HTTP API using authentication keys to retrieve performance results\n",
        "\n",
        "Run Apache Benchmark for 10 times, producing output similar to:\n",
        "\n",
        "```\n",
        "This is ApacheBench, Version 2.3 <$Revision: 1843412 $>\n",
        "Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/\n",
        "Licensed to The Apache Software Foundation, http://www.apache.org/\n",
        "\n",
        "Benchmarking 8530a665-66f3-49c8-a953-b82a2d312917.eastus.azurecontainer.io (be patient)...INFO: POST header ==\n",
        "---\n",
        "POST /score HTTP/1.0\n",
        "Content-length: 812\n",
        "Content-type: application/json\n",
        "Authorization: Bearer Agb3D23IygXXXXXXXXXXXXXXXXXXXXXXXXX\n",
        "Host: 8530a665-66f3-49c8-a953-b82a2d312917.eastus.azurecontainer.io\n",
        "User-Agent: ApacheBench/2.3\n",
        "Accept: */*\n",
        "\n",
        "\n",
        "---\n",
        "LOG: header received:\n",
        "HTTP/1.0 200 OK\n",
        "Content-Length: 33\n",
        "Content-Type: application/json\n",
        "Date: Thu, 30 Jul 2020 12:33:34 GMT\n",
        "Server: nginx/1.10.3 (Ubuntu)\n",
        "X-Ms-Request-Id: babfc511-a0f0-4ecb-a243-b3010a76b8b9\n",
        "X-Ms-Run-Function-Failed: False\n",
        "\n",
        "\"{\\\"result\\\": [\\\"yes\\\", \\\"no\\\"]}\"\n",
        "LOG: Response code = 200\n",
        "\n",
        "..done\n",
        "\n",
        "Server Software:        nginx/1.10.3\n",
        "Server Hostname:        8530a665-66f3-49c8-a953-b82a2d312917.eastus.azurecontainer.io\n",
        "Server Port:            80\n",
        "\n",
        "Document Path:          /score\n",
        "Document Length:        33 bytes\n",
        "\n",
        "Concurrency Level:      1\n",
        "Time taken for tests:   1.599 seconds\n",
        "Complete requests:      10\n",
        "Failed requests:        0\n",
        "Total transferred:      2600 bytes\n",
        "Total body sent:        10560\n",
        "HTML transferred:       330 bytes\n",
        "Requests per second:    6.25 [#/sec] (mean)\n",
        "Time per request:       159.918 [ms] (mean)\n",
        "Time per request:       159.918 [ms] (mean, across all concurrent requests)\n",
        "Transfer rate:          1.59 [Kbytes/sec] received\n",
        "                        6.45 kb/s sent\n",
        "                        8.04 kb/s total\n",
        "\n",
        "Connection Times (ms)\n",
        "              min  mean[+/-sd] median   max\n",
        "Connect:       21   23   0.8     23      24\n",
        "Processing:    92  137  28.3    151     176\n",
        "Waiting:       92  137  28.3    151     176\n",
        "Total:        114  160  28.0    172     199\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "source": [
        "## 10. Optional: Cleanup\n",
        "Not required, but i think this is really important in production"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "cpu_cluster.delete()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.8.5-final",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.5 64-bit",
      "metadata": {
        "interpreter": {
          "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
        }
      }
    },
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}